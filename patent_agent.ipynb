{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0617f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15cd560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk(text,prefix):\n",
    "    \n",
    "    CHUNK_PROMPT=\"\"\"\n",
    "    You are a semantic document chunker working on patent data. The content below is from a section of a patent document (e.g., abstract, description, claims, etc.).\n",
    "\n",
    "    Your task is to:\n",
    "    - Split the section into multiple coherent **semantic chunks**, labeled from `chunk_1` to `chunk_N`.\n",
    "    - Each chunk should be **approximately 300–400 words**, depending on content flow.\n",
    "    - If the input section is too short for multiple chunks, return just one chunk.\n",
    "    - Maintain original wording and structure — **do not summarize or paraphrase**.\n",
    "    - Ensure each chunk captures a meaningful segment (e.g., full idea, concept, implementation detail).\n",
    "    - Each chunk should be logically self-contained and usable independently.\n",
    "    - Do NOT put json directly into chunks , convert into a paragraph with all information\n",
    "\n",
    "    NOTE: Do NOT use your information just use whatever is given \n",
    "    Return the output in the following JSON format:\n",
    "\n",
    "\n",
    "    [\n",
    "    {\n",
    "        \"chunk_id\": \"chunk_1\",\n",
    "        \"chunk_text\": \"...\"\n",
    "    },\n",
    "    {\n",
    "        \"chunk_id\": \"chunk_2\",\n",
    "        \"chunk_text\": \"...\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    CHUNK_PROMPT += f\"\\nADD THIS PREFIX IN EACH CHUNK ID: {prefix}_\"\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        input=[\n",
    "            {\"role\": \"system\",\"content\": CHUNK_PROMPT},\n",
    "            {\"role\": \"user\",\"content\": json.dumps(text,indent=2)},\n",
    "        ],\n",
    "    )\n",
    "    response=response.output_text\n",
    "    response=json.loads(response.strip().strip(\"'\"))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab45c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_chunks(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf8\") as file:\n",
    "        file_json = json.load(file)\n",
    "\n",
    "    # Safely extract major sections\n",
    "    root = file_json.get(\"us-patent-application\", {})\n",
    "\n",
    "    us_bibliographic_data_application = root.get(\"us-bibliographic-data-application\", {})\n",
    "    abstract = root.get(\"abstract\", {})\n",
    "    # drawings = root.get(\"drawings\", {})\n",
    "    description = root.get(\"description\", {})\n",
    "    claims = root.get(\"claims\", {})\n",
    "\n",
    "    other_info = {\n",
    "        \"language\": root.get(\"@lang\", \"N/A\"),\n",
    "        \"dtd_version\": root.get(\"@dtd-version\", \"N/A\"),\n",
    "        \"file\": root.get(\"@file\", \"N/A\"),\n",
    "        \"status\": root.get(\"@status\", \"N/A\"),\n",
    "        \"id\": root.get(\"@id\", \"N/A\"),\n",
    "        \"country\": root.get(\"@country\", \"N/A\"),\n",
    "        \"date_produced\": root.get(\"@date-produced\", \"N/A\"),\n",
    "        \"date_published\": root.get(\"@date-publ\", \"N/A\")\n",
    "    }\n",
    "    chunks = {\n",
    "        \"meta_data\": get_chunk(other_info,\"meta_data\"),\n",
    "        \"us-bibliographic-data-application\": get_chunk(us_bibliographic_data_application,\"us-bibliographic-data-application\"),\n",
    "        \"abstract\": get_chunk(abstract,\"abstract\"),\n",
    "        # \"drawings\": get_chunk(drawings),\n",
    "        \"description\": get_chunk(description,\"description\"),\n",
    "        \"claims\": get_chunk(claims,\"claims\")\n",
    "    }\n",
    "\n",
    "    return chunks,other_info[\"file\"]\n",
    "\n",
    "# Example usage:\n",
    "# create_chunks(\"your_patent_file.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f4cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks,file_id=create_chunks(\"D:\\Desktop\\Projects\\Research Agent\\patent.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6614de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks['us-bibliographic-data-application']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30367bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path=\"D:\\Desktop\\Projects\\Research Agent\\\\test.txt\"\n",
    "with open(text_path,\"r\",encoding=\"utf8\") as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_verifier(json_ouput):\n",
    "    \n",
    "\n",
    "    OUTPUT_VERIFIER = \"\"\"\n",
    "    If the model output is  like this:\n",
    "    {\n",
    "        \"chunks\": {\n",
    "            ...\n",
    "        }\n",
    "    }\n",
    "    Then return \"Yes\", otherwise return \"No\".\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-2025-04-14\",\n",
    "        input=[\n",
    "            {\"role\": \"system\",\"content\": OUTPUT_VERIFIER},\n",
    "            {\"role\": \"user\",\"content\": json_ouput},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68bc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865337fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
